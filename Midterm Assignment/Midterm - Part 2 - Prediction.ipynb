{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhinav\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from webbot import Browser\n",
    "from zipfile import ZipFile\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from IPython.core.display import HTML\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate(user='tiwari.abhi@husky.neu.edu', password='Ctr|hEpW'):\n",
    "    global web\n",
    "    web = Browser()\n",
    "    web.go_to(\"https://freddiemac.embs.com/FLoan/secure/login.php?pagename=download2\")\n",
    "    web.type(user, into='email')\n",
    "    web.type(password, into='password')\n",
    "    web.click('Submit Credentials')\n",
    "    web.click('Yes')\n",
    "    web.click('Continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_quarter_str(quarter_str='Q22005'):\n",
    "    try:\n",
    "        quarter_int = int(quarter_str[1:2])\n",
    "        \n",
    "        if quarter_int <= 0:\n",
    "            print('Quarter cannot be lesser than or equal to zero')\n",
    "            exit(0)\n",
    "        \n",
    "        year = int(quarter_str[2:])\n",
    "        \n",
    "    except:\n",
    "        print('Cannot Parse Quarter/Year to Int Value')\n",
    "        exit(0)\n",
    "    \n",
    "    next_quarter = quarter_int + 1\n",
    "    \n",
    "    if next_quarter > 4:\n",
    "        next_quarter = 1\n",
    "        year = year + 1\n",
    "    \n",
    "    next_quarter_str = 'Q'+ str(next_quarter) + str(year)\n",
    "    return next_quarter_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_both_quarter_data(current_quarter,next_quarter):\n",
    "    \n",
    "    quarters = [current_quarter,next_quarter]\n",
    "    \n",
    "    global file_names\n",
    "    file_names = []\n",
    "    \n",
    "    for q in quarters:\n",
    "        web.click('historical_data1_{}.zip'.format(q))\n",
    "        file_names.append('historical_data1_{}.zip'.format(q))\n",
    "        time.sleep(60)\n",
    "    \n",
    "    global download_path\n",
    "    download_path = ''\n",
    "    path_list = os.getcwd().split('\\\\')[:3]\n",
    "\n",
    "    for item in path_list:\n",
    "        download_path = download_path + item + '\\\\'\n",
    "\n",
    "    download_path = download_path + 'Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assure_path_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zipped_files_to_cwd(path_to_downloaded_files):\n",
    "    global folder_path_all_files\n",
    "    folder_path_all_files = os.getcwd() + '\\\\' + 'Extracted Quarterly Files'\n",
    "    zip_ref = zipfile.ZipFile(path_to_downloaded_files, 'r')\n",
    "    assure_path_exists(folder_path_all_files)\n",
    "    zip_ref.extractall(folder_path_all_files)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNAN_orig(df):\n",
    "    df['fico'] = df['fico'].fillna(0)\n",
    "    df['flag_fthb'] = df['flag_fthb'].fillna('X')\n",
    "    df['cd_msa'] = df['cd_msa'].fillna(0)\n",
    "    df['mi_pct'] = df['mi_pct'].fillna(0)\n",
    "    df['cnt_units'] = df['cnt_units'].fillna(0)\n",
    "    df['occpy_sts'] = df['occpy_sts'].fillna('X')\n",
    "    df['cltv'] = df['cltv'].fillna(0)\n",
    "    df['dti'] = df['dti'].fillna(0)\n",
    "    df['ltv'] = df['ltv'].fillna(0)\n",
    "    df['channel'] = df['channel'].fillna('X')\n",
    "    df['ppmt_pnlty'] = df['ppmt_pnlty'].fillna('X')\n",
    "    df['prop_type'] = df['prop_type'].fillna('XX')\n",
    "    df['zipcode'] = df['zipcode'].fillna(0)\n",
    "    df['loan_purpose'] = df['loan_purpose'].fillna('X')\n",
    "    df['cnt_borr'] = df['cnt_borr'].fillna(0)\n",
    "    df['flag_sc'] = df['flag_sc'].fillna('N')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changedatatype_orig(df):\n",
    "    # Change the data types for all column\n",
    "    df[['fico', 'cd_msa', 'mi_pct', 'cnt_borr', 'cnt_units', 'cltv', 'dti', 'orig_upb', 'ltv', 'zipcode',\n",
    "        'orig_loan_term']] = df[['fico', 'cd_msa', 'mi_pct', 'cnt_borr', 'cnt_units', 'cltv', 'dti', 'orig_upb', 'ltv', 'zipcode','orig_loan_term']].astype('int64')\n",
    "    df[['flag_sc', 'servicer_name']] = df[['flag_sc', 'servicer_name']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Origination_Quarter_File(historic_orig_files):\n",
    "    writeHeader1 = True\n",
    "\n",
    "    abc = glob.glob(historic_orig_files)\n",
    "    xyz = glob.glob(folder_path_all_files + \"/historical_data1_time_*.txt\")\n",
    "    \n",
    "    #Get Rid of all the paths that point to the historical_data1_time_files\n",
    "    for item in xyz:\n",
    "        abc.remove(item)\n",
    "    \n",
    "    for f in abc:\n",
    "        sample_df = pd.read_csv(f, sep=\"|\",\n",
    "                                names=['fico', 'dt_first_pi', 'flag_fthb', 'dt_matr', 'cd_msa', \"mi_pct\",\n",
    "                                       'cnt_units', 'occpy_sts', 'cltv', 'dti', 'orig_upb', 'ltv', 'int_rt',\n",
    "                                       'channel', 'ppmt_pnlty', 'prod_type', 'st', 'prop_type', 'zipcode',\n",
    "                                       'id_loan', 'loan_purpose', 'orig_loan_term', 'cnt_borr', 'seller_name',\n",
    "                                       'servicer_name', 'flag_sc'], skipinitialspace=True, low_memory=False)\n",
    "        \n",
    "        sample_df = fillNAN_orig(sample_df)\n",
    "        sample_df = changedatatype_orig(sample_df)\n",
    "        \n",
    "        sample_df['Year'] = ['19' + x if x == '99' else '20' + x for x in (sample_df['id_loan'].apply(lambda x: x[2:4]))]\n",
    "        \n",
    "        #Get historical File name\n",
    "        file_name = f.split('\\\\')[-1].split('.')[0]\n",
    "        \n",
    "        sample_df.to_csv(file_name + '.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAllReqColumns(df):\n",
    "    cols_to_keep = ['fico','flag_fthbN','flag_fthbX','flag_fthbY','mi_pct','cnt_units','occpy_stsl','occpy_stsO','occpy_stsS','cltv','dti','orig_upb','ltv','int_rt','channelB','channelC','channelR','channelT','ppmt_pnltyN','ppmt_pnltyX','ppmt_pnltyY','prop_typeCO','prop_typeCP','prop_typeLH','prop_typeMH','prop_typePU','prop_typeSF','prop_typeXX','loan_purposeC','loan_purposeN','loan_purposeP','orig_loan_term','cnt_borr']\n",
    "    \n",
    "    for x in cols_to_keep:\n",
    "        if not x in df.columns:\n",
    "            df[x] = 0.0\n",
    "            \n",
    "    df = df._get_numeric_data()\n",
    "    df.drop('cd_msa',axis=1,inplace=True)\n",
    "    df.drop('dt_first_pi',axis=1,inplace=True)\n",
    "    df.drop('dt_matr',axis=1,inplace=True)\n",
    "    df.drop('flag_sc',axis=1,inplace=True)\n",
    "    df.drop('zipcode',axis=1,inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_model(df):\n",
    "    dummies1 = pd.get_dummies(df['flag_fthb']).rename(columns=lambda x: 'flag_fthb' + str(x))\n",
    "    train_df = pd.concat([df, dummies1], axis=1)\n",
    "    \n",
    "    dummies2 = pd.get_dummies(df['occpy_sts']).rename(columns=lambda x: 'occpy_sts' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies2], axis=1)\n",
    "    \n",
    "    dummies3 = pd.get_dummies(df['channel']).rename(columns=lambda x: 'channel' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies3], axis=1)\n",
    "    \n",
    "    dummies4 = pd.get_dummies(df['ppmt_pnlty']).rename(columns=lambda x: 'ppmt_pnlty' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies4], axis=1)\n",
    "    \n",
    "    dummies5 = pd.get_dummies(df['prop_type']).rename(columns=lambda x: 'prop_type' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies5], axis=1)\n",
    "    \n",
    "    dummies6 = pd.get_dummies(df['loan_purpose']).rename(columns=lambda x: 'loan_purpose' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies6], axis=1)\n",
    "    \n",
    "    train_df['flag_sc'] = train_df['flag_sc'].map({'Y':1,'N':0})\n",
    "    \n",
    "    train_df = checkAllReqColumns(train_df)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(current_year_df,next_year_df):\n",
    "    global lm\n",
    "    X_train = current_year_df.drop('int_rt', axis=1)\n",
    "    y_train = current_year_df['int_rt']\n",
    "    X_test = next_year_df.drop('int_rt', axis=1)\n",
    "    y_test = next_year_df['int_rt']\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    \n",
    "    lm.fit(X_train,y_train)\n",
    "    \n",
    "    reg_pred_train = lm.predict(X_train)\n",
    "    reg_pred_test = lm.predict(X_test)\n",
    "    \n",
    "    print('-Training Metrics-')\n",
    "    compute_metrics(lm,reg_pred_train,y_train)\n",
    "    print('-Testing Metrics-')\n",
    "    compute_metrics(lm,reg_pred_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf_model(current_year_df,next_year_df):\n",
    "    global rf\n",
    "    X_train = current_year_df.drop('int_rt', axis=1)\n",
    "    y_train = current_year_df['int_rt']\n",
    "    X_test = next_year_df.drop('int_rt', axis=1)\n",
    "    y_test = next_year_df['int_rt']\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    \n",
    "    rf.fit(X_train,y_train)\n",
    "    \n",
    "    rf_pred_train = rf.predict(X_train)\n",
    "    rf_pred_test = rf.predict(X_test)\n",
    "    \n",
    "    print('-Training Metrics-')\n",
    "    compute_metrics(rf,rf_pred_train,y_train)\n",
    "    print('-Testing Metrics-')\n",
    "    compute_metrics(rf,rf_pred_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(current_year_df,next_year_df):\n",
    "    global nn\n",
    "    X_train = current_year_df.drop('int_rt', axis=1)\n",
    "    y_train = current_year_df['int_rt']\n",
    "    X_test = next_year_df.drop('int_rt', axis=1)\n",
    "    y_test = next_year_df['int_rt']\n",
    "\n",
    "    nn = MLPRegressor()\n",
    "    \n",
    "    nn.fit(X_train,y_train)\n",
    "    \n",
    "    nn_pred_train = nn.predict(X_train)\n",
    "    nn_pred_test = nn.predict(X_test)\n",
    "    \n",
    "    print('-Training Metrics-')\n",
    "    compute_metrics(nn,nn_pred_train,y_train)\n",
    "    print('-Testing Metrics-')\n",
    "    compute_metrics(nn,nn_pred_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model,predicted_val,true_val):\n",
    "    RSq = r2_score(true_val,predicted_val)\n",
    "    print('R Squared: ' + str(RSq))\n",
    "    MAE = mean_absolute_error(true_val,predicted_val)\n",
    "    print('MAE: ' + str(MAE))\n",
    "    RMS = np.sqrt(mean_squared_error(true_val,predicted_val))\n",
    "    print('RMS: ' + str(RMS))\n",
    "    MAPE = np.mean(np.abs((true_val - predicted_val) / true_val)) * 100\n",
    "    print('MAPE: ' + str(MAPE))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_selection(model,processed_curr_df,processed_next_df):\n",
    "    global sfs_fwd\n",
    "    sfs_fwd = SFS(model, k_features = 25, forward=True, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    #Feature Selection on Current Quarter Data\n",
    "    sfs_fwd = sfs_fwd.fit(processed_curr_df.drop('int_rt',axis=1),processed_curr_df['int_rt'])\n",
    "    \n",
    "    print('----Selected Features from FWD Search----')\n",
    "    print(sfs_fwd.k_feature_names_)\n",
    "    \n",
    "    X_train_sfs = sfs_fwd.transform(processed_curr_df.drop('int_rt',axis=1))\n",
    "    X_test_sfs = sfs_fwd.transform(processed_next_df.drop('int_rt',axis=1))\n",
    "    \n",
    "    y_train_sfs = processed_curr_df['int_rt']\n",
    "    y_test_sfs = processed_next_df['int_rt']\n",
    "    \n",
    "    model.fit(X_train_sfs,y_train_sfs)\n",
    "    \n",
    "    fwd_pred_train = model.predict(X_train_sfs)\n",
    "    fwd_pred_test = model.predict(X_test_sfs)\n",
    "    \n",
    "    print('-Training Metrics-')\n",
    "    compute_metrics(model,fwd_pred_train,y_train_sfs)\n",
    "    print('-Testing Metrics-')\n",
    "    compute_metrics(model,fwd_pred_test,y_test_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bwd_selection(model,processed_curr_df,processed_next_df):\n",
    "    global sfs_bwd\n",
    "    sfs_bwd = SFS(model, k_features = 30, forward=False, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    #Feature Selection on Current Quarter Data\n",
    "    sfs_bwd = sfs_bwd.fit(processed_curr_df.drop('int_rt',axis=1).values,processed_curr_df['int_rt'].values)\n",
    "    \n",
    "    print('----Selected Features from BWD Search----')\n",
    "    print(sfs_bwd.k_feature_names_)\n",
    "    \n",
    "    X_train_sfs = sfs_bwd.transform(processed_curr_df.drop('int_rt',axis=1))\n",
    "    X_test_sfs = sfs_bwd.transform(processed_next_df.drop('int_rt',axis=1))\n",
    "    \n",
    "    y_train_sfs = processed_curr_df['int_rt']\n",
    "    y_test_sfs = processed_next_df['int_rt']\n",
    "    \n",
    "    model.fit(X_train_sfs,y_train_sfs.values)\n",
    "    \n",
    "    bwd_pred_train = model.predict(X_train_sfs)\n",
    "    bwd_pred_test = model.predict(X_test_sfs)\n",
    "    \n",
    "    print('-Training Metrics-')\n",
    "    compute_metrics(model,bwd_pred_train,y_train_sfs)\n",
    "    print('-Testing Metrics-')\n",
    "    compute_metrics(model,bwd_pred_test,y_test_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exh_selection(model,processed_curr_df,processed_next_df):\n",
    "    global efs_exh\n",
    "    efs_exh = EFS(model, min_features=10, max_features=12, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    #Feature Selection on Current Quarter Data\n",
    "    efs_exh = efs_exh.fit(processed_curr_df.drop('int_rt',axis=1),processed_curr_df['int_rt'])\n",
    "    \n",
    "    print('----Selected Features from Exhaustive Search----')\n",
    "    print(efs_exh.k_feature_names_)\n",
    "    \n",
    "    X_train_efs = efs_exh.transform(processed_curr_df.drop('int_rt',axis=1))\n",
    "    X_test_efs = efs_exh.transform(processed_next_df.drop('int_rt',axis=1))\n",
    "    \n",
    "    y_train_efs = processed_curr_df['int_rt']\n",
    "    y_test_efs = processed_next_df['int_rt']\n",
    "    \n",
    "    model.fit(X_train_efs,y_train_efs)\n",
    "    \n",
    "    exh_pred_train = model.predict(X_train_efs)\n",
    "    exh_pred_test = model.predict(X_test_sfs)\n",
    "    \n",
    "    print('-Training Metrics-')\n",
    "    compute_metrics(model,exh_pred_train,y_train_sfs)\n",
    "    print('-Testing Metrics-')\n",
    "    compute_metrics(model,exh_pred_test,y_test_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinancialCrisisEconomicBoomCheck(current_year_df,next_year_df):\n",
    "    global rf_FcEb\n",
    "    X_train = current_year_df.drop('int_rt', axis=1)\n",
    "    y_train = current_year_df['int_rt']\n",
    "    X_test = next_year_df.drop('int_rt', axis=1)\n",
    "    y_test = next_year_df['int_rt']\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    \n",
    "    rf.fit(X_train,y_train)\n",
    "    \n",
    "    rf_pred_train = rf.predict(X_train)\n",
    "    rf_pred_test = rf.predict(X_test)\n",
    "    \n",
    "    print('-Training Metrics-')\n",
    "    compute_metrics(rf,rf_pred_train,y_train)\n",
    "    print('-Testing Metrics-')\n",
    "    compute_metrics(rf,rf_pred_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global current_quarter,current_qtr_df,next_qtr_df,processed_curr_df,processed_next_df\n",
    "#     ts = time.time()\n",
    "#     st = datetime.datetime.fromtimestamp(ts).strftime('%Y%m%d_%H%M%S')\n",
    "#     args = sys.argv[1:]\n",
    "\n",
    "#     print(\"Starting\")\n",
    "\n",
    "#     counter = 0\n",
    "#     if len(args) == 0:\n",
    "#         print(\"No input arguments..Exiting!\")\n",
    "#         exit(0)\n",
    "\n",
    "#     for arg in args:\n",
    "#         if counter == 0:\n",
    "#             user = str(arg)\n",
    "#         elif counter == 1:\n",
    "#             password = str(arg)\n",
    "#         elif counter == 2:\n",
    "#             current_quarter = str(arg)\n",
    "#         counter += 1\n",
    "\n",
    "#     print(\"Email Address: \" + user)\n",
    "#     print(\"Password: \" + password)\n",
    "#     print(\"Downloading data for Current Quarter: \" + current_quarter)\n",
    "\n",
    "    #navigate(user, password)\n",
    "    navigate()\n",
    "    \n",
    "    current_quarter = 'Q12005'\n",
    "        \n",
    "    next_quarter = get_next_quarter_str(current_quarter)\n",
    "    \n",
    "    if int(next_quarter[2:]) not in list(range(2005,2017)):\n",
    "        print(\"The Quarters requested are out of range\")\n",
    "        exit(0)\n",
    "    \n",
    "    get_both_quarter_data(current_quarter,next_quarter)\n",
    "    \n",
    "    for file in file_names:\n",
    "        extract_zipped_files_to_cwd(download_path + '\\\\' + file)\n",
    "\n",
    "#     print('Path where all files have been extracted : {}'.format(folder_path_all_files))\n",
    "    \n",
    "    get_Origination_Quarter_File(folder_path_all_files + \"/historical_data1_*.txt\")\n",
    "    \n",
    "    current_qtr_df = pd.read_csv(file_names[0].split('.')[0] + '.csv',low_memory=False)\n",
    "    next_qtr_df = pd.read_csv(file_names[1].split('.')[0] + '.csv',low_memory=False)\n",
    "    \n",
    "    processed_curr_df = prepare_data_for_model(current_qtr_df)\n",
    "    processed_next_df = prepare_data_for_model(next_qtr_df)\n",
    "    \n",
    "    #Training all 3 Models on all features\n",
    "    print('--------Metrics for Quarters {} & {} when all features included--------'.format(current_quarter,next_quarter))\n",
    "    print('--Linear Model--')\n",
    "    train_linear_model(processed_curr_df,processed_next_df)\n",
    "    print('--Random Forrest Model--')\n",
    "    train_rf_model(processed_curr_df,processed_next_df)\n",
    "    print('--Neural Network Model--')\n",
    "    train_nn_model(processed_curr_df,processed_next_df)\n",
    "    \n",
    "    #Training all 3 Models using Forward Selection\n",
    "    print('--------Metrics for Quarters {} & {} using Step Wise Forward Selection--------'.format(current_quarter,next_quarter))\n",
    "    print('--Linear Model--')\n",
    "    fwd_selection(lm,processed_curr_df,processed_next_df)\n",
    "    print('--Random Forrest Model--')\n",
    "    fwd_selection(rf,processed_curr_df,processed_next_df)\n",
    "    print('--Neural Network Model--')\n",
    "    fwd_selection(nn,processed_curr_df,processed_next_df)\n",
    "    \n",
    "    #Training all 3 Models using Backward Selection\n",
    "    print('--------Metrics for Quarters {} & {} using Step Wise Backward Selection--------'.format(current_quarter,next_quarter))\n",
    "    print('--Linear Model--')\n",
    "    bwd_selection(lm,processed_curr_df,processed_next_df)\n",
    "    print('--Random Forrest Model--')\n",
    "    bwd_selection(rf,processed_curr_df,processed_next_df)\n",
    "    print('--Neural Network Model--')\n",
    "    bwd_selection(nn,processed_curr_df,processed_next_df)\n",
    "    \n",
    "#     #Training all 3 Models using Exhaustive Selection\n",
    "#     print('--------Metrics for Quarters {} & {} using Exhaustive Selection--------'.format(current_quarter,next_quarter))\n",
    "#     print('--Linear Model--')\n",
    "#     exh_selection(lm,processed_curr_df,processed_next_df)\n",
    "#     print('--Random Forrest Model--')\n",
    "#     exh_selection(rf,processed_curr_df,processed_next_df)\n",
    "#     print('--Neural Network Model--')\n",
    "#     exh_selection(nn,processed_curr_df,processed_next_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Metrics for Quarters Q12005 & Q22005 when all features included--------\n",
      "--Linear Model--\n",
      "-Training Metrics-\n",
      "R Squared: 0.37824718717748795\n",
      "MAE: 0.2135798637598435\n",
      "RMS: 0.28998513312818\n",
      "MAPE: 3.7789997405837688\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: 0.14139996798842236\n",
      "MAE: 0.2478038471138564\n",
      "RMS: 0.3248587101740584\n",
      "MAPE: 4.226463669216197\n",
      "\n",
      "\n",
      "--Random Forrest Model--\n",
      "-Training Metrics-\n",
      "R Squared: 0.8875034763191897\n",
      "MAE: 0.08696171081588172\n",
      "RMS: 0.1233492192629221\n",
      "MAPE: 1.5391540896470053\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: 0.11093903748203171\n",
      "MAE: 0.2565043865366303\n",
      "RMS: 0.33057106439907963\n",
      "MAPE: 4.387649529888035\n",
      "\n",
      "\n",
      "--Neural Network Model--\n",
      "-Training Metrics-\n",
      "R Squared: -377.68721250290895\n",
      "MAE: 6.438398621149193\n",
      "RMS: 7.156607082483858\n",
      "MAPE: 114.66300859241971\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: -422.2381503111184\n",
      "MAE: 6.4763422176493775\n",
      "RMS: 7.212593718933191\n",
      "MAPE: 112.90362404342736\n",
      "\n",
      "\n",
      "--------Metrics for Quarters Q12005 & Q22005 using Step Wise Forward Selection--------\n",
      "--Linear Model--\n",
      "----Selected Features from FWD Search----\n",
      "('fico', 'mi_pct', 'cnt_units', 'orig_upb', 'ltv', 'orig_loan_term', 'cnt_borr', 'Year', 'flag_fthbN', 'flag_fthbY', 'occpy_stsI', 'occpy_stsP', 'occpy_stsS', 'channelT', 'ppmt_pnltyN', 'prop_typeCO', 'prop_typeCP', 'prop_typeMH', 'loan_purposeC', 'loan_purposeN', 'loan_purposeP', 'flag_fthbX', 'occpy_stsl', 'occpy_stsO', 'prop_typeLH')\n",
      "-Training Metrics-\n",
      "R Squared: 0.37578469953954297\n",
      "MAE: 0.2137363480849155\n",
      "RMS: 0.2905588170295989\n",
      "MAPE: 3.781493586814121\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: 0.1387088493410591\n",
      "MAE: 0.2477951753046037\n",
      "RMS: 0.3253674158239672\n",
      "MAPE: 4.22543964475919\n",
      "\n",
      "\n",
      "--Random Forrest Model--\n",
      "----Selected Features from FWD Search----\n",
      "('mi_pct', 'cnt_units', 'orig_upb', 'orig_loan_term', 'Year', 'flag_fthb9', 'flag_fthbN', 'flag_fthbY', 'occpy_stsI', 'occpy_stsP', 'occpy_stsS', 'channelB', 'channelC', 'ppmt_pnltyN', 'ppmt_pnltyX', 'ppmt_pnltyY', 'prop_type99', 'prop_typeCP', 'prop_typeMH', 'loan_purposeP', 'flag_fthbX', 'occpy_stsl', 'occpy_stsO', 'prop_typeLH', 'prop_typeXX')\n",
      "-Training Metrics-\n",
      "R Squared: 0.46953148846706716\n",
      "MAE: 0.1994062483785697\n",
      "RMS: 0.2678530885828854\n",
      "MAPE: 3.5350285682359512\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: 0.11782277920225614\n",
      "MAE: 0.25459746344250644\n",
      "RMS: 0.3292888195244901\n",
      "MAPE: 4.347957126289271\n",
      "\n",
      "\n",
      "--Neural Network Model--\n",
      "----Selected Features from FWD Search----\n",
      "('mi_pct', 'cnt_units', 'cltv', 'ltv', 'orig_loan_term', 'flag_fthb9', 'flag_fthbN', 'flag_fthbY', 'occpy_stsI', 'occpy_stsP', 'occpy_stsS', 'channelB', 'channelR', 'channelT', 'ppmt_pnltyX', 'prop_type99', 'prop_typeCO', 'prop_typeMH', 'prop_typePU', 'loan_purposeC', 'loan_purposeP', 'occpy_stsl', 'occpy_stsO', 'prop_typeLH', 'prop_typeXX')\n",
      "-Training Metrics-\n",
      "R Squared: 0.17530356682133186\n",
      "MAE: 0.258083799256947\n",
      "RMS: 0.3339749641901554\n",
      "MAPE: 4.649114561436204\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: -0.05861581657755388\n",
      "MAE: 0.24314404229053857\n",
      "RMS: 0.3607183657259195\n",
      "MAPE: 4.2357458318432375\n",
      "\n",
      "\n",
      "--------Metrics for Quarters Q12005 & Q22005 using Step Wise Backward Selection--------\n",
      "--Linear Model--\n",
      "----Selected Features from BWD Search----\n",
      "('0', '1', '2', '5', '6', '7', '8', '9', '10', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '24', '25', '26', '29', '31', '32', '33', '34', '35', '36')\n",
      "-Training Metrics-\n",
      "R Squared: 0.3778787159275897\n",
      "MAE: 0.21371984314934345\n",
      "RMS: 0.29007104778433945\n",
      "MAPE: 3.781508563465947\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: 0.14062073419563847\n",
      "MAE: 0.2478800878028751\n",
      "RMS: 0.3250060916474583\n",
      "MAPE: 4.227709284455065\n",
      "\n",
      "\n",
      "--Random Forrest Model--\n",
      "----Selected Features from BWD Search----\n",
      "('0', '1', '3', '4', '5', '6', '7', '8', '10', '11', '12', '13', '15', '17', '18', '19', '20', '21', '22', '23', '26', '27', '28', '29', '31', '32', '33', '34', '35', '36')\n",
      "-Training Metrics-\n",
      "R Squared: 0.8880832697604804\n",
      "MAE: 0.08691824422485286\n",
      "RMS: 0.12303094518753406\n",
      "MAPE: 1.5385608489297216\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: 0.11066153592879946\n",
      "MAE: 0.25648606472699087\n",
      "RMS: 0.3306226507528862\n",
      "MAPE: 4.387522363096214\n",
      "\n",
      "\n",
      "--Neural Network Model--\n",
      "----Selected Features from BWD Search----\n",
      "('0', '1', '6', '7', '8', '9', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '28', '29', '30', '31', '32', '33', '34', '35', '36')\n",
      "-Training Metrics-\n",
      "R Squared: -62.59739204989725\n",
      "MAE: 2.0988235438642047\n",
      "RMS: 2.932827414886532\n",
      "MAPE: 36.73053922892332\n",
      "\n",
      "\n",
      "-Testing Metrics-\n",
      "R Squared: -72.56261166262217\n",
      "MAE: 2.234036587422103\n",
      "RMS: 3.0069598908488726\n",
      "MAPE: 38.3177760811722\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
